A terminalâ€‘based AI assistant that supports both **text** and **voice** interaction in Indian regional languages. Current pipeline:

```
User (voice/text, regional) â†’ Whisper (ASR) â†’ Deepâ€‘Translator â†’ GPTâ€‘3.5/4 â†’ gTTS (TTS) â†’ Audio/Text reply
```

---

## âœ¨ Features

| Capability | Details |
|------------|---------|
| **Voice input** | Local Whisper transcribes speech; autoâ€‘detects language |
| **Text input**  | Direct CLI prompt |
| **Language detection** | Whisper (voice) & `langdetect` (text) |
| **Translation** | `deepâ€‘translator` converts regional â†’ English |
| **LLM chat** | OpenAI GPTâ€‘3.5 by default (memory buffer retained per session) |
| **Voice reply** | gTTS speaks GPT reply in same regional language |
| **Modes** | Chosen once per session (`text`Â orÂ `voice`) |

---

## ğŸ—‚ï¸ Project Structure

```
voicebot/
â”œâ”€â”€ main.py            # Orchestrator with conversation loop
â”œâ”€â”€ input_handler.py   # Handles text/voice input + language detection
â”œâ”€â”€ transcriber.py     # Whisper transcription + mic recording
â”œâ”€â”€ translator.py      # Regional â†’ English translation (deepâ€‘translator)
â”œâ”€â”€ llm_client.py      # OpenAI GPT client (v1 SDK)
â”œâ”€â”€ tts.py             # gTTS speech synthesis + playback
â”œâ”€â”€ utils.py           # Helper (audio playback)
â””â”€â”€ requirements.txt
```

---

## ğŸ”§ Tools & Libraries

| Stage | Library / Service | Notes |
|-------|-------------------|-------|
| ASR   | `whisper`         | Local model, language autoâ€‘detect |
| Record| `sounddevice`, `scipy` | Capture mic & save WAV |
| Lâ€‘Detect | `langdetect`   | Textâ€‘only fallback |
| Translate | `deepâ€‘translator` | Google Translate backend |
| LLM   | `openai>=1.x`     | GPTâ€‘3.5 / GPTâ€‘4, memory buffer supported |
| TTS   | `gTTS`            | Free TTS; good Hindi, weaker Kannada |
| Audio | `ffmpeg` / `ffplay` | Playback of MP3/WAV |

---

## âš™ï¸ Installation

```bash
# Create and activate venv
python3 -m venv voicebot-env
source voicebot-env/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# System packages (Ubuntu)
sudo apt update
sudo apt install ffmpeg portaudio19-dev python3-pyaudio
```

`requirements.txt` contents:
```
openai
whisper
torch
sounddevice
scipy
deep-translator
langdetect
gTTS
```

---

## ğŸ”‘ Environment Variables

Set your OpenAI key once:
```bash
export OPENAI_API_KEY="sk-..."
```

---

## ğŸš€ Usage

```bash
python3 main.py
# Choose input mode: text or voice
```
- **Exit** any time by typing `exit` (text mode) or saying the word â€œexitâ€ (voice mode).

---

## ğŸ›£ï¸ Roadmap

1. Replace gTTS with higherâ€‘quality Kannada TTS (Google Cloud TTS / Bhashini)
2. Persist memory across sessions (simple JSON storage)
3. Add transcript logging per session
4. Optional GUI (Gradio) or Flask API wrapper